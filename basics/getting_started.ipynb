{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Creation\n",
    "PyTorch has API designed in Numpy Style for making the life of beginners easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.1118  0.0959  0.9752\n",
       " 0.8469  0.3039  0.6482\n",
       " 0.9310  0.7859  0.1154\n",
       " 0.5732  0.0528  0.9782\n",
       " 0.7521  0.1328  0.8212\n",
       "[torch.FloatTensor of size 5x3]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "1.00000e-37 *\n",
       " -2.7429  0.0005  4.6774\n",
       "  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000\n",
       "[torch.FloatTensor of size 5x3]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.rand(5, 3)\n",
    "y = torch.rand(5, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy Like Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.4569  0.7753  1.1837\n",
       " 1.5705  0.1422  0.7490\n",
       " 0.6570  0.2623  0.7471\n",
       " 1.4993  1.3699  0.6686\n",
       " 0.3614  1.2243  1.8354\n",
       "[torch.FloatTensor of size 5x3]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.5091  0.4318\n",
       " 0.9586  0.1386\n",
       " 0.5518  0.1113\n",
       " 0.8788  0.9859\n",
       " 0.0940  0.4532\n",
       "[torch.FloatTensor of size 5x2]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:, :2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy Bridge\n",
    "If you are coming from numpy background, you can still code in numpy and where you think you need a support of a framework or GPU, migrate your data to PyTorch and take it back when you need it there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.94783938,  0.34351015,  0.41133446],\n",
       "       [ 0.61181039,  0.00358355,  0.01855606],\n",
       "       [ 0.10520189,  0.1510013 ,  0.05143904],\n",
       "       [ 0.62046349,  0.38401294,  0.14046863],\n",
       "       [ 0.26745191,  0.77107751,  0.99292314]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_x = x.numpy()\n",
    "type(numpy_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'> <class 'torch.FloatTensor'>\n"
     ]
    }
   ],
   "source": [
    "torch_x = torch.from_numpy(numpy_x)\n",
    "print(type(torch_x), type(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.4569  0.7753  1.1837\n",
       " 1.5705  0.1422  0.7490\n",
       " 0.6570  0.2623  0.7471\n",
       " 1.4993  1.3699  0.6686\n",
       " 0.3614  1.2243  1.8354\n",
       "[torch.FloatTensor of size 5x3]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.4569  0.7753  1.1837\n",
       " 1.5705  0.1422  0.7490\n",
       " 0.6570  0.2623  0.7471\n",
       " 1.4993  1.3699  0.6686\n",
       " 0.3614  1.2243  1.8354\n",
       "[torch.cuda.FloatTensor of size 5x3 (GPU 0)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.cuda()\n",
    "y = y.cuda()\n",
    "x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create GPU tensors instead of moving to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.cuda.FloatTensor(5,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Variable, Function and AutoGrad\n",
    "These are the core components of Pytorch. If you get em right, you are PRO, from day 1.\n",
    "- Variables keep the track of your graph\n",
    "- Functions are the OPS which communicate to other variables and keep your graph acyclic\n",
    "- Backward() function (or autograd) do the backward pass following the history saved in the variables and creates the grad for you. Don't worry, PyTorch follows python philosophy, It won't update your parameters implicitly. It will store the gradients in .grad variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.Tensor([12.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad:  None\n",
      "x.data:  \n",
      " 12.3000\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = Variable(x, requires_grad=True)\n",
    "print('x.grad: ', x.grad)\n",
    "print('x.data: ', x.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = (x ** x) * (x - 2)\n",
    "z = F.tanh(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad:  Variable containing:\n",
      " 0\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "x.data:  \n",
      " 12.3000\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('x.grad: ', x.grad)\n",
    "print('x.data: ', x.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creator\n",
    "Creators keep the track of your graph for autograd to do backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creator of z:  <torch.nn._functions.thnn.auto.Tanh object at 0x7fa01a8809e8>\n",
      "creator of creator of z:  <torch.autograd._functions.basic_ops.Mul object at 0x7fa01a880c88>\n",
      "creator of creator of creator of z:  <torch.autograd._functions.basic_ops.Pow object at 0x7fa07b22dba8>\n"
     ]
    }
   ],
   "source": [
    "print('creator of z: ', z.creator)\n",
    "print('creator of creator of z: ', z.creator.previous_functions[0][0])\n",
    "print('creator of creator of creator of z: ', z.creator.previous_functions[0][0].previous_functions[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
